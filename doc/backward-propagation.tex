\documentclass{article}

\usepackage{fullpage,amsmath,amsthm,amssymb}

\newcommand{\R}{\mathbb{R}}

\title{Gradient Descent for Neural Nets}
\author{D\'avid P\'al}

\begin{document}

We start by defining several functions.
We first define logistic sigmoid function, $\sigma:\R \to (0,1)$,
$$
\sigma(z) = \frac{1}{1 + e^{-z}} \qquad z \in \R \; .
$$
Its derivative is
$$
\sigma'(z) = ??
$$

\end{document}
